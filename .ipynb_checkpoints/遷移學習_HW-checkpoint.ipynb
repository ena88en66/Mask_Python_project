{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Layers for FNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "# Layers for CNN\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "# For data preprocessing\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 使用Fashion_mnist資料集 -- 讀取資料並進行資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load fashion_mnist\n",
    "(X_train, y_train0), (X_test, y_test0) = datasets.fashion_mnist.load_data()\n",
    "\n",
    "# 檢視圖片的樣子\n",
    "idx = np.random.randint(X_train.shape[0])\n",
    "X_sample = X_train[idx]\n",
    "y_sample = y_train0[idx].squeeze()\n",
    "\n",
    "plt.imshow(X_sample)\n",
    "plt.title([y_sample])\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and reshape the range of features\n",
    "X_train = X_train.reshape(60000,28,28,1)/255\n",
    "X_test = X_test.reshape(10000,28,28,1)/255\n",
    "\n",
    "# One-hot encoding\n",
    "y_train = to_categorical(y_train0, 10)\n",
    "y_test = to_categorical(y_test0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.建立分類 Fashion_mnist 的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 模型CNN部分：有3個conv2D+Maxpooling及1個conv2D+GlobalAveragePooling2D\n",
    "* 模型全連結層部分：一層50個神經元、一層250個神經元、最後一層為輸出層，有10個神經元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_layers = [Conv2D(32, (3, 3), input_shape=(28, 28, 1), padding='same', activation='relu', name='Conv_1'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(64, (3, 3), padding='same', activation='relu', name='Conv_2'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(128, (3, 3), padding='same', activation='relu', name='Conv_3'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(256, (3, 3), padding='same', activation='relu', name='Conv_4'),\n",
    "              GlobalAveragePooling2D()]\n",
    "FC_layers = [Dense(units=50, activation='relu'),\n",
    "             Dense(units=250, activation='relu'),\n",
    "             Dense(units=10, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x20fcecf4ba8>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x20fcecf4fd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x20fcecf7240>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x20fcecf7668>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x20fcecf7860>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x20fcecf7d30>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x20fcecf7f28>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x20fcecf6390>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x20fcecf4b70>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x20fcecf6748>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x20fcecf6a20>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_layers + FC_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv_4 (Conv2D)              (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 50)                12850     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 250)               12750     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                2510      \n",
      "=================================================================\n",
      "Total params: 415,950\n",
      "Trainable params: 415,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(CNN_layers + FC_layers) #組裝模型\n",
    "model.summary() #模型摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(),\n",
    "              metrics=['categorical_accuracy']) #編譯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 67s 1ms/sample - loss: 1.0484 - categorical_accuracy: 0.5979 - val_loss: 0.7429 - val_categorical_accuracy: 0.7153\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 66s 1ms/sample - loss: 0.6159 - categorical_accuracy: 0.7669 - val_loss: 0.5755 - val_categorical_accuracy: 0.7881\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 66s 1ms/sample - loss: 0.5231 - categorical_accuracy: 0.8055 - val_loss: 0.5036 - val_categorical_accuracy: 0.8190\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 66s 1ms/sample - loss: 0.4554 - categorical_accuracy: 0.8343 - val_loss: 0.4617 - val_categorical_accuracy: 0.8285\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 66s 1ms/sample - loss: 0.4198 - categorical_accuracy: 0.8459 - val_loss: 0.4247 - val_categorical_accuracy: 0.8445\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 66s 1ms/sample - loss: 0.3819 - categorical_accuracy: 0.8611 - val_loss: 0.3842 - val_categorical_accuracy: 0.8639\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 67s 1ms/sample - loss: 0.3521 - categorical_accuracy: 0.8724 - val_loss: 0.3520 - val_categorical_accuracy: 0.8732\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 66s 1ms/sample - loss: 0.3367 - categorical_accuracy: 0.8760 - val_loss: 0.3654 - val_categorical_accuracy: 0.8662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20fceea5dd8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=500,epochs=8,validation_data=(X_test,y_test)) #訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Fashion_1.h5') #儲存模型權重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.load_weights('Fashion_1.h5')\n",
    "\n",
    "score_train = model.evaluate(X_train, y_train) #評估訓練資料準確率\n",
    "\n",
    "score_test = model.evaluate(X_test, y_test) #評估測試資料準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 87.68500089645386\n",
      "Test Accuracy: 86.61999702453613\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.使用遷移學習的方法來建立模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 載入Mnist資料及並對其進行資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Mnist data\n",
    "(U_train, v_train0), (U_test, v_test0) = datasets.mnist.load_data()\n",
    "\n",
    "# 檢視圖片的樣子\n",
    "idx = np.random.randint(U_train.shape[0])\n",
    "U_sample = U_train[idx]\n",
    "v_sample = v_train0[idx].squeeze()\n",
    "\n",
    "plt.imshow(U_sample)\n",
    "plt.title([v_sample])\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the range of features and reshape size\n",
    "U_train = U_train.reshape(60000,28,28,1)/255\n",
    "U_test = U_test.reshape(10000,28,28,1)/255\n",
    "\n",
    "# One-hot encoding\n",
    "v_train = to_categorical(v_train0, 10)\n",
    "v_test = to_categorical(v_test0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 利用transfer learning建立Mnist的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From LeNet-5 for Fashion_mnist\n",
    "CNN_layers #CNN是跟別人借來的\n",
    "\n",
    "# New FC layers for Mnist\n",
    "FC_layers_Mnist = [Dense(units=128, activation='relu'),\n",
    "                   Dense(units=256, activation='relu'),\n",
    "                   Dense(units=10, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv_4 (Conv2D)              (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 456,330\n",
      "Trainable params: 456,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_Mnist = Sequential(CNN_layers+FC_layers_Mnist) #組裝模型\n",
    "model_Mnist.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv_4 (Conv2D)              (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 50)                12850     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 250)               12750     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                2510      \n",
      "=================================================================\n",
      "Total params: 415,950\n",
      "Trainable params: 415,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model與model_Mnist的差異：後面的全連結層不同，前面的卷積與持化層(CNN部分)相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Frozen法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in CNN_layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv_4 (Conv2D)              (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 456,330\n",
      "Trainable params: 68,490\n",
      "Non-trainable params: 387,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_Mnist.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Mnist.compile(loss='categorical_crossentropy', \n",
    "                    optimizer=Adam(),\n",
    "                    metrics=['categorical_accuracy']) #編譯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 24s 397us/sample - loss: 1.0505 - categorical_accuracy: 0.6709 - val_loss: 0.5771 - val_categorical_accuracy: 0.8171\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 23s 390us/sample - loss: 0.5163 - categorical_accuracy: 0.8328 - val_loss: 0.4324 - val_categorical_accuracy: 0.8579\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 23s 377us/sample - loss: 0.4131 - categorical_accuracy: 0.8662 - val_loss: 0.3566 - val_categorical_accuracy: 0.8872\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 23s 378us/sample - loss: 0.3507 - categorical_accuracy: 0.8877 - val_loss: 0.2976 - val_categorical_accuracy: 0.9032\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 23s 379us/sample - loss: 0.3168 - categorical_accuracy: 0.8970 - val_loss: 0.2999 - val_categorical_accuracy: 0.9028\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 22s 373us/sample - loss: 0.2865 - categorical_accuracy: 0.9083 - val_loss: 0.2473 - val_categorical_accuracy: 0.9240\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 22s 373us/sample - loss: 0.2634 - categorical_accuracy: 0.9167 - val_loss: 0.2392 - val_categorical_accuracy: 0.9231\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 23s 380us/sample - loss: 0.2449 - categorical_accuracy: 0.9215 - val_loss: 0.2416 - val_categorical_accuracy: 0.9220\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 23s 377us/sample - loss: 0.2338 - categorical_accuracy: 0.9251 - val_loss: 0.2153 - val_categorical_accuracy: 0.9340\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 22s 373us/sample - loss: 0.2226 - categorical_accuracy: 0.9293 - val_loss: 0.1848 - val_categorical_accuracy: 0.9423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20fae6abe10>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Mnist.fit(U_train, v_train,\n",
    "                batch_size=500, \n",
    "                epochs=10,\n",
    "                validation_data=(U_test, v_test)\n",
    "                ) #訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score_train = model.evaluate(X_train, y_train) #評估訓練資料準確率\n",
    "\n",
    "score_test = model.evaluate(X_test, y_test) #評估測試資料準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:87.68500089645386\n",
      "Test Accuracy: 86.61999702453613\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Accuracy:{score_train[1]*100}') \n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 在Frozen情況下：model_Mnist和model的Train Accuracy、Test Accuracy相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Fine-tune法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in CNN_layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv_4 (Conv2D)              (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "Total params: 68,490\n",
      "Trainable params: 68,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_Mnist.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Mnist.compile(loss='categorical_crossentropy', \n",
    "                    optimizer=Adam(),\n",
    "                    metrics=['categorical_accuracy']) #編譯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 0.6087 - categorical_accuracy: 0.8584 - val_loss: 0.1212 - val_categorical_accuracy: 0.9602\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 72s 1ms/sample - loss: 0.1113 - categorical_accuracy: 0.9664 - val_loss: 0.0723 - val_categorical_accuracy: 0.9747\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 68s 1ms/sample - loss: 0.0744 - categorical_accuracy: 0.9772 - val_loss: 0.0735 - val_categorical_accuracy: 0.9762\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 73s 1ms/sample - loss: 0.0624 - categorical_accuracy: 0.9804 - val_loss: 0.0465 - val_categorical_accuracy: 0.9845\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 0.0489 - categorical_accuracy: 0.9849 - val_loss: 0.0408 - val_categorical_accuracy: 0.9869\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 0.0398 - categorical_accuracy: 0.9871 - val_loss: 0.0358 - val_categorical_accuracy: 0.9882\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 0.0368 - categorical_accuracy: 0.9882 - val_loss: 0.0364 - val_categorical_accuracy: 0.9881\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 74s 1ms/sample - loss: 0.0303 - categorical_accuracy: 0.9902 - val_loss: 0.0404 - val_categorical_accuracy: 0.9871\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 70s 1ms/sample - loss: 0.0263 - categorical_accuracy: 0.9919 - val_loss: 0.0284 - val_categorical_accuracy: 0.9907\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 70s 1ms/sample - loss: 0.0215 - categorical_accuracy: 0.9933 - val_loss: 0.0399 - val_categorical_accuracy: 0.9870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20fcd466c88>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Mnist.fit(U_train, v_train,\n",
    "                batch_size=500, \n",
    "                epochs=10,\n",
    "                validation_data=(U_test, v_test)\n",
    "                ) #訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score_train = model.evaluate(X_train, y_train) #評估訓練資料準確率\n",
    "\n",
    "score_test = model.evaluate(X_test, y_test) #評估測試資料準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 73.26499819755554\n",
      "Test Accuracy: 72.57999777793884\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 使用Fine tune方法的情況下：model_Mnist和model的Train Accuracy、Test Accuracy確實不同！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.模型結果與結論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型：\n",
    "* 第一個model：\n",
    "    * 模型設定：\n",
    "        - 有四個卷積+池化層：前三個池化層都是Maxpooling、最後一個池化層是GlobalAveragePooling\n",
    "        - FC層的神經元個數分別為50、250、10\n",
    "        - activation只有模型最後輸出層為softmax，其他都是relu\n",
    "        - loss function使用categorical_crossentropy、optimizer用Adam\n",
    "        - batch_size=500、訓練次數為8次\n",
    "    * 訓練結果：\n",
    "        - 訓練資料準確率：0.8760\n",
    "        - 測試資料準確率：0.8662\n",
    "        - 沒有overfitting\n",
    "* 使用遷移學習(model_Mnist)\n",
    "    * 模型設定：\n",
    "        - 有四個卷積+池化層：前三個池化層都是Maxpooling、最後一個池化層是GlobalAveragePooling\n",
    "        - FC層的神經元個數分別為128、256、10\n",
    "        - activation只有模型最後輸出層為softmax，其他都是relu\n",
    "        - loss function使用categorical_crossentropy、optimizer用Adam\n",
    "        - batch_size=500、訓練次數為10次\n",
    "    * 訓練結果--採用Frozen方法：\n",
    "        - 訓練資料準確率：0.9293\n",
    "        - 測試資料準確率：0.9423\n",
    "        - 沒有overfitting\n",
    "        - 訓練速度很快(一次23秒)\n",
    "    * 訓練結果--採用Fine-tune方法：\n",
    "        - 訓練資料準確率：0.9933\n",
    "        - 測試資料準確率：0.9870\n",
    "        - 沒有overfitting\n",
    "        - 訓練速度比用Frozen慢一點(一次70秒)、但準確率比它高\n",
    "#### 結論：使用遷移學習的Frozen方式訓練模型真的很快速，訓練時間為Fine-tune方式的1/3，而且兩者的準確率都很高。\n",
    "    #### 遷移學習可以把別的模型訓練優質的部分放到另一個模型很有趣也很實用！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
